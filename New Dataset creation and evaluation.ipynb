{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10,9\n",
    "sb.set_style('whitegrid')\n",
    "\n",
    "# Authenticate to Twitter\n",
    "customer_key = \"cht3zkzkhKtCXadYO8a7fCa4E\"\n",
    "customer_key_secret = \"oN4KLrQOqYjKjJpS7b8C7kvKhNpCSrMOYT1vxjjciWmGGxGKmJ\"\n",
    "access_token = \"1300264439929663488-Vy4BHsechVLPxB48tksIfTMdt7S8Mr\"\n",
    "access_token_secret = \"BafJQS8QHxSK8v7NF5hSMS9PmrSmsCuM1ZSVSmoZ24uBu\"\n",
    "    \n",
    "auth = tweepy.OAuthHandler(customer_key, customer_key_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "# Create API object\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "try:\n",
    "        api.verify_credentials()\n",
    "        print(\"Authentication OK\")\n",
    "except:\n",
    "        print(\"Error during authentication\")\n",
    "    \n",
    "tweet = pd.DataFrame([tweet._json['text'] for tweet in tweepy.Cursor(api.user_timeline, screen_name = 'BillGates').items()]\n",
    "                         ,columns = ['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here in Washington, we always vote by mail. It's a safe and secure way to shape the future of our country. But rega… https://t.co/wGSCJYxxY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@MohamedBinZayed The UAE is an essential partner in stopping polio in Pakistan. Thank you @MohamedBinZayed for your… https://t.co/5xQEZ8CpUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For decades, @Rotary has worked tirelessly to #EndPolio. Today, the health infrastructure they’ve built around the… https://t.co/vYYV7djNsE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @StephenCurry30: Even with his busy schedule, Dr. Fauci took the time to sit down with me (AGAIN) and talk about what we’ve gotten right…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’ve been working for some time on a book about what we need to do over the next decade to avoid a climate disaster… https://t.co/UvV6cRjxOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>Students from KIPP Academy in the Bronx produced a video with questions. I answered some of them on Gates Notes - http://bit.ly/aBhI21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>Melinda's TEDx talk has posted on the TED site - http://bit.ly/bWlsyD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>My notes on “Energy Transitions” - http://bit.ly/bF6pTr - a book by Vaclav Smil, one of my favorite writers on energy.  More coming…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>Sal from www.khanacademy.org came by to meet with us.  A short video on the gates notes website - http://bit.ly/98sHQw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>View of a small section of the BYD Shenzhen plant.  The scale of the operation is incredible http://yfrog.com/5c1cvj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet\n",
       "0     Here in Washington, we always vote by mail. It's a safe and secure way to shape the future of our country. But rega… https://t.co/wGSCJYxxY1\n",
       "1     @MohamedBinZayed The UAE is an essential partner in stopping polio in Pakistan. Thank you @MohamedBinZayed for your… https://t.co/5xQEZ8CpUL\n",
       "2      For decades, @Rotary has worked tirelessly to #EndPolio. Today, the health infrastructure they’ve built around the… https://t.co/vYYV7djNsE\n",
       "3     RT @StephenCurry30: Even with his busy schedule, Dr. Fauci took the time to sit down with me (AGAIN) and talk about what we’ve gotten right…\n",
       "4     I’ve been working for some time on a book about what we need to do over the next decade to avoid a climate disaster… https://t.co/UvV6cRjxOW\n",
       "...                                                                                                                                            ...\n",
       "3195        Students from KIPP Academy in the Bronx produced a video with questions. I answered some of them on Gates Notes - http://bit.ly/aBhI21\n",
       "3196                                                                         Melinda's TEDx talk has posted on the TED site - http://bit.ly/bWlsyD\n",
       "3197          My notes on “Energy Transitions” - http://bit.ly/bF6pTr - a book by Vaclav Smil, one of my favorite writers on energy.  More coming…\n",
       "3198                        Sal from www.khanacademy.org came by to meet with us.  A short video on the gates notes website - http://bit.ly/98sHQw\n",
       "3199                          View of a small section of the BYD Shenzhen plant.  The scale of the operation is incredible http://yfrog.com/5c1cvj\n",
       "\n",
       "[3200 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "tweet.shape\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanTxt(text):\n",
    " text = re.sub('@[A-Za-z0–9]+', '', text) #Removing @mentions\n",
    " text = re.sub('#', '', text) # Removing '#' hash tag\n",
    " text = re.sub('RT[\\s]+', '', text) # Removing RT\n",
    " text = re.sub('https?:\\/\\/\\S+', '', text) # Removing hyperlink\n",
    " \n",
    " return text\n",
    "\n",
    "# Clean the tweets\n",
    "tweet['tweet'] = tweet['tweet'].apply(cleanTxt)\n",
    "\n",
    "j =1\n",
    "sentence = []\n",
    "for i in tweet['tweet']:\n",
    "    i = i.replace('.','.\\n')\n",
    "    separated_string = i.splitlines()\n",
    "    for k in separated_string:\n",
    "        if not k.strip():\n",
    "                continue\n",
    "        else:\n",
    "            sentence.append(k)\n",
    "        j = j+1\n",
    "\n",
    "tweetdata = pd.DataFrame(sentence,columns = ['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here in Washington, we always vote by mail.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's a safe and secure way to shape the future of our country.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But rega…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The UAE is an essential partner in stopping polio in Pakistan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you  for your…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5510</th>\n",
       "      <td>khanacademy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>org came by to meet with us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5512</th>\n",
       "      <td>A short video on the gates notes website -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>View of a small section of the BYD Shenzhen plant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>The scale of the operation is incredible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5515 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                tweet\n",
       "0                         Here in Washington, we always vote by mail.\n",
       "1      It's a safe and secure way to shape the future of our country.\n",
       "2                                                          But rega… \n",
       "3      The UAE is an essential partner in stopping polio in Pakistan.\n",
       "4                                               Thank you  for your… \n",
       "...                                                               ...\n",
       "5510                                                     khanacademy.\n",
       "5511                                     org came by to meet with us.\n",
       "5512                      A short video on the gates notes website - \n",
       "5513               View of a small section of the BYD Shenzhen plant.\n",
       "5514                        The scale of the operation is incredible \n",
       "\n",
       "[5515 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "tweetdata['tweet'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here in Washington, we always vote by mail.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's a safe and secure way to shape the future of our country.</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But rega…</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The UAE is an essential partner in stopping polio in Pakistan.</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you  for your…</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5510</th>\n",
       "      <td>khanacademy.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>org came by to meet with us.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5512</th>\n",
       "      <td>A short video on the gates notes website -</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>View of a small section of the BYD Shenzhen plant.</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>The scale of the operation is incredible</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5515 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                tweet  \\\n",
       "0                         Here in Washington, we always vote by mail.   \n",
       "1      It's a safe and secure way to shape the future of our country.   \n",
       "2                                                          But rega…    \n",
       "3      The UAE is an essential partner in stopping polio in Pakistan.   \n",
       "4                                               Thank you  for your…    \n",
       "...                                                               ...   \n",
       "5510                                                     khanacademy.   \n",
       "5511                                     org came by to meet with us.   \n",
       "5512                      A short video on the gates notes website -    \n",
       "5513               View of a small section of the BYD Shenzhen plant.   \n",
       "5514                        The scale of the operation is incredible    \n",
       "\n",
       "      Subjectivity  polarity  \n",
       "0         0.000000      0.00  \n",
       "1         0.408333      0.30  \n",
       "2         0.000000      0.00  \n",
       "3         0.300000      0.00  \n",
       "4         0.000000      0.00  \n",
       "...            ...       ...  \n",
       "5510      0.000000      0.00  \n",
       "5511      0.000000      0.00  \n",
       "5512      0.300000      0.00  \n",
       "5513      0.400000     -0.25  \n",
       "5514      0.900000      0.90  \n",
       "\n",
       "[5515 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def populateSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def populatePolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "tweetdata['Subjectivity'] = tweetdata.tweet.apply(populateSubjectivity)\n",
    "tweetdata['polarity'] = tweetdata.tweet.apply(populatePolarity)\n",
    "tweetdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here in Washington, we always vote by mail.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's a safe and secure way to shape the future of our country.</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But rega…</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The UAE is an essential partner in stopping polio in Pakistan.</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you  for your…</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5510</th>\n",
       "      <td>khanacademy.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>org came by to meet with us.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5512</th>\n",
       "      <td>A short video on the gates notes website -</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>View of a small section of the BYD Shenzhen plant.</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>The scale of the operation is incredible</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5515 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                tweet  \\\n",
       "0                         Here in Washington, we always vote by mail.   \n",
       "1      It's a safe and secure way to shape the future of our country.   \n",
       "2                                                          But rega…    \n",
       "3      The UAE is an essential partner in stopping polio in Pakistan.   \n",
       "4                                               Thank you  for your…    \n",
       "...                                                               ...   \n",
       "5510                                                     khanacademy.   \n",
       "5511                                     org came by to meet with us.   \n",
       "5512                      A short video on the gates notes website -    \n",
       "5513               View of a small section of the BYD Shenzhen plant.   \n",
       "5514                        The scale of the operation is incredible    \n",
       "\n",
       "      Subjectivity  polarity  label  \n",
       "0         0.000000      0.00      1  \n",
       "1         0.408333      0.30      1  \n",
       "2         0.000000      0.00      1  \n",
       "3         0.300000      0.00      1  \n",
       "4         0.000000      0.00      1  \n",
       "...            ...       ...    ...  \n",
       "5510      0.000000      0.00      1  \n",
       "5511      0.000000      0.00      1  \n",
       "5512      0.300000      0.00      1  \n",
       "5513      0.400000     -0.25      0  \n",
       "5514      0.900000      0.90      1  \n",
       "\n",
       "[5515 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def result(Score):\n",
    "    if Score<0:\n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "tweetdata['label'] = tweetdata.polarity.apply(result)\n",
    "tweetdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "\n",
    "import numbers\n",
    "import numpy as np\n",
    "\n",
    "from torchmoji.create_vocab import extend_vocab, VocabBuilder\n",
    "from torchmoji.word_generator import WordGenerator\n",
    "from torchmoji.global_variables import SPECIAL_TOKENS\n",
    "\n",
    "# import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "class SentenceTokenizer_validation():\n",
    "    \"\"\" Create numpy array of tokens corresponding to input sentences.\n",
    "        The vocabulary can include Unicode tokens.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocabulary, fixed_length, custom_wordgen=None,\n",
    "                 ignore_sentences_with_only_custom=False, masking_value=0,\n",
    "                 unknown_value=1):\n",
    "        \"\"\" Needs a dictionary as input for the vocabulary.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(vocabulary) > np.iinfo('uint16').max:\n",
    "            raise ValueError('Dictionary is too big ({} tokens) for the numpy '\n",
    "                             'datatypes used (max limit={}). Reduce vocabulary'\n",
    "                             ' or adjust code accordingly!'\n",
    "                             .format(len(vocabulary), np.iinfo('uint16').max))\n",
    "\n",
    "        # Shouldn't be able to modify the given vocabulary\n",
    "        self.vocabulary = deepcopy(vocabulary)\n",
    "        self.fixed_length = fixed_length\n",
    "        self.ignore_sentences_with_only_custom = ignore_sentences_with_only_custom\n",
    "        self.masking_value = masking_value\n",
    "        self.unknown_value = unknown_value\n",
    "\n",
    "        # Initialized with an empty stream of sentences that must then be fed\n",
    "        # to the generator at a later point for reusability.\n",
    "        # A custom word generator can be used for domain-specific filtering etc\n",
    "        if custom_wordgen is not None:\n",
    "            assert custom_wordgen.stream is None\n",
    "            self.wordgen = custom_wordgen\n",
    "            self.uses_custom_wordgen = True\n",
    "        else:\n",
    "            self.wordgen = WordGenerator(None, allow_unicode_text=True,\n",
    "                                         ignore_emojis=False,\n",
    "                                         remove_variation_selectors=True,\n",
    "                                         break_replacement=True)\n",
    "            self.uses_custom_wordgen = False\n",
    "\n",
    "    def tokenize_sentences(self, sentences, reset_stats=True, max_sentences=None):\n",
    "\n",
    "        if max_sentences is None and not hasattr(sentences, '__len__'):\n",
    "            raise ValueError('Either you must provide an array with a length'\n",
    "                             'attribute (e.g. a list) or specify the maximum '\n",
    "                             'length yourself using `max_sentences`!')\n",
    "        n_sentences = (max_sentences if max_sentences is not None\n",
    "                       else len(sentences))\n",
    "\n",
    "        if self.masking_value == 0:\n",
    "            tokens = np.zeros((n_sentences, self.fixed_length), dtype='uint16')\n",
    "        else:\n",
    "            tokens = (np.ones((n_sentences, self.fixed_length), dtype='uint16')\n",
    "                      * self.masking_value)\n",
    "\n",
    "        if reset_stats:\n",
    "            self.wordgen.reset_stats()\n",
    "\n",
    "        # With a custom word generator info can be extracted from each\n",
    "        # sentence (e.g. labels)\n",
    "        infos = []\n",
    "\n",
    "        # Returns words as strings and then map them to vocabulary\n",
    "        self.wordgen.stream = sentences\n",
    "        next_insert = 0\n",
    "        n_ignored_unknowns = 0\n",
    "        for s_words, s_info in self.wordgen:\n",
    "            s_tokens = self.find_tokens(s_words)\n",
    "\n",
    "            if (self.ignore_sentences_with_only_custom and\n",
    "                np.all([True if t < len(SPECIAL_TOKENS)\n",
    "                        else False for t in s_tokens])):\n",
    "                n_ignored_unknowns += 1\n",
    "                continue\n",
    "            if len(s_tokens) > self.fixed_length:\n",
    "                s_tokens = s_tokens[:self.fixed_length]\n",
    "            tokens[next_insert,:len(s_tokens)] = s_tokens\n",
    "            infos.append(s_info)\n",
    "            next_insert += 1\n",
    "\n",
    "        # For standard word generators all sentences should be tokenized\n",
    "        # this is not necessarily the case for custom wordgenerators as they\n",
    "        # may filter the sentences etc.\n",
    "        if not self.uses_custom_wordgen and not self.ignore_sentences_with_only_custom:\n",
    "            assert len(sentences) == next_insert\n",
    "        else:\n",
    "            # adjust based on actual tokens received\n",
    "            tokens = tokens[:next_insert]\n",
    "            infos = infos[:next_insert]\n",
    "\n",
    "        return tokens, infos, self.wordgen.stats\n",
    "\n",
    "    def find_tokens(self, words):\n",
    "        assert len(words) > 0\n",
    "        tokens = []\n",
    "        for w in words:\n",
    "            try:\n",
    "                tokens.append(self.vocabulary[w])\n",
    "            except KeyError:\n",
    "                tokens.append(self.unknown_value)\n",
    "        return tokens\n",
    "    \n",
    "    def split_train_val_test(self, sentences, info_dicts,\n",
    "                             split_parameter=[0], extend_with=0):\n",
    "        if isinstance(split_parameter, list) and \\\n",
    "                all(isinstance(x, list) for x in split_parameter) and \\\n",
    "                len(split_parameter) == 3:\n",
    "            # Helper function to verify provided indices are numbers in range\n",
    "            def verify_indices(inds):\n",
    "                return list(filter(lambda i: isinstance(i, numbers.Number)\n",
    "                            and i < len(sentences), inds))\n",
    "            ind_val = verify_indices(split_parameter[0])\n",
    "        else:\n",
    "            ind_val = list(range(len(sentences)))\n",
    "            \n",
    "        val = np.array([sentences[x] for x in ind_val])\n",
    "        info_val = np.array([info_dicts[x] for x in ind_val])\n",
    "\n",
    "        added = 0\n",
    "        # Extend vocabulary with training set tokens\n",
    "        if extend_with > 0:\n",
    "            wg = WordGenerator(val)\n",
    "            vb = VocabBuilder(wg)\n",
    "            vb.count_all_words()\n",
    "            added = extend_vocab(self.vocabulary, vb, max_tokens=extend_with)\n",
    "\n",
    "        # Wrap results\n",
    "        result = [self.tokenize_sentences(s)[0] for s in [val]]\n",
    "        result_infos = [info_val]\n",
    "        # if type(result_infos[0][0]) in [np.double, np.float, np.int64, np.int32, np.uint8]:\n",
    "        #     result_infos = [torch.from_numpy(label).long() for label in result_infos]\n",
    "\n",
    "        return result, result_infos, added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_benchmarktest(vocab, extend_with=0):\n",
    "    batch_size, maxlen = calculate_batchsize_maxlen(tweetdata['tweet'])\n",
    "    st = SentenceTokenizer_validation(vocab, maxlen)\n",
    "    texts, labels, added = st.split_train_val_test(tweetdata['tweet'],\n",
    "                                                   tweetdata['label'],\n",
    "                                                   extend_with=extend_with)\n",
    "    return {'texts': texts,\n",
    "            'labels': labels,\n",
    "            'added': added,\n",
    "            'batch_size': batch_size,\n",
    "            'maxlen': maxlen}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmoji.tokenizer import tokenize\n",
    "import math\n",
    "def calculate_batchsize_maxlen(texts):\n",
    "    def roundup(x):\n",
    "        return int(math.ceil(x / 10.0)) * 10\n",
    "    lengths = [len(tokenize(t)) for t in texts]\n",
    "    maxlen = roundup(np.percentile(lengths, 80.0))\n",
    "    batch_size = 250 if maxlen <= 100 else 50\n",
    "    return batch_size, maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def evaluate_using_acc(model, test_gen):\n",
    "    # Validate on test_data\n",
    "    model.eval()\n",
    "    accs = []\n",
    "    output = []\n",
    "    for i, data in enumerate(test_gen):\n",
    "        x, y = data\n",
    "        outs = model(x)\n",
    "        if model.nb_classes > 2:\n",
    "            pred = torch.max(outs, 1)[1]\n",
    "            acc = accuracy_score(y.squeeze().numpy(), pred.squeeze().numpy())\n",
    "        else:\n",
    "            pred = torch.argmax(outs, 1)\n",
    "            acc = (pred == y).double().sum() / len(pred)\n",
    "            output.append(pred)\n",
    "        accs.append(acc)\n",
    "    return np.mean(accs),output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for embed.weight\n",
      "Loading weights for lstm_0.weight_ih_l0\n",
      "Loading weights for lstm_0.weight_hh_l0\n",
      "Loading weights for lstm_0.bias_ih_l0\n",
      "Loading weights for lstm_0.bias_hh_l0\n",
      "Loading weights for lstm_0.weight_ih_l0_reverse\n",
      "Loading weights for lstm_0.weight_hh_l0_reverse\n",
      "Loading weights for lstm_0.bias_ih_l0_reverse\n",
      "Loading weights for lstm_0.bias_hh_l0_reverse\n",
      "Loading weights for lstm_1.weight_ih_l0\n",
      "Loading weights for lstm_1.weight_hh_l0\n",
      "Loading weights for lstm_1.bias_ih_l0\n",
      "Loading weights for lstm_1.bias_hh_l0\n",
      "Loading weights for lstm_1.weight_ih_l0_reverse\n",
      "Loading weights for lstm_1.weight_hh_l0_reverse\n",
      "Loading weights for lstm_1.bias_ih_l0_reverse\n",
      "Loading weights for lstm_1.bias_hh_l0_reverse\n",
      "Loading weights for attention_layer.attention_vector\n",
      "Ignoring weights for output_layer.0.weight\n",
      "Ignoring weights for output_layer.0.bias\n",
      "0.9220238095238095\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import json\n",
    "from torchmoji.model_def import torchmoji_transfer\n",
    "from torchmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH, ROOT_PATH\n",
    "from torchmoji.finetuning import (finetune,get_data_loader)\n",
    "\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "        vocab = json.load(f)\n",
    "nb_classes = 2\n",
    "# Load dataset.\n",
    "test_gen = load_benchmarktest(vocab)\n",
    "#test_gen\n",
    "model = torchmoji_transfer(nb_classes, PRETRAINED_PATH)\n",
    "test_gen = get_data_loader(test_gen['texts'][0], test_gen['labels'][0], 100,\n",
    "                              extended_batch_sampler=False)\n",
    "Acc, pred = evaluate_using_acc(model,test_gen)\n",
    "\n",
    "print(Acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
